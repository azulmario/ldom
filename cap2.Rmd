##

Reporte completo del análisis del rendimiento ante la base proporcionada para prueba de ubicación de domicilios.

## Recomendaciones generales para optimizar el funcionamiento

Para un mejor aprovechamiento del sistema de "Localización automatizada de domicilios geográficos"  <localhost:13838/ldom>, se recomienda lo siguiente:

- Hacer una prueba previa con pocos datos, unos 10, para verificar que se estén utilizando correctamente los campos de entrada.
- El archivo de Excel puede contener fórmulas para construir las variables de entrada, por ejemplo: '=SI(Q9,Q9,R9)' para juntar las variables S_NUM_EXT y S_LETRA_EXT. O bien '=EXTRAEB(E2,7,100)' para acortar un texto.
- La variable n es opcional, ya que si se omite se genera una variable que es un número consecutivo.

```{r, eval=FALSE, include=FALSE}
## Pruebas de rendimiento
source("qmaps.R", echo = FALSE)
padron <- lee("P20160302.xlsx", 1)
test <- function(n = NULL) {
  if(is.null(n)) {
    require(random)
    n <- randomNumbers(1, 1, length(padron$n), 1)
  }
  dom = padron[n, ]
  s_ <- Sys.time()
  a_ <- identifica(dom)
  b_ <- podar(a_)
  c_ <- atomizar(b_)
  e_ <- Sys.time()
  c( e_ - s_, entropia(a_), entropia(b_), entropia(c_), c_$niv, c_$BM)
}
ad <- NULL
for(var in c(1:600))
  ad <- rbind(ad, test())
colnames(ad)[c(1,2,5,6)] <- c("Entropía", "Tiempo", "Nivel", "Error")
write_feather(as.data.frame(ad), "ad.data")
```

```{r}
require(feather)
ad <- read_feather("ad.data")
ad$Nivel <- factor(ad$Nivel, labels = c("Número exterior", "Entrecalle", "Calle", "Colonia", "Localidad"))
require(ggplot2)
```

## Tiempo de ejecución

El tiempo de ejecución con 1 procesador tiene la siguiente distribución en segundos:
```{r}
  summary(ad$Tiempo)
```

##
```{r}
qplot(ad$Tiempo, geom="histogram", bins = 40) +
  labs(title="Distribución del tiempo de ejecución") +
  labs(x="Tiempo en segundos", y="Cantidad")
```

Por lo anterior se recomienda tener el mayor número de procesadores disponibles para la máquina virtual.

## Entropía informática

Utilizando el principio de entropía informática (Shannon 1951),
que mide el grado de aleatoriedad e incertidumbre
de los datos, también puede verse como una medida del desorden.
La entropía observada presenta la siguiente distribución:

```{r}
  summary(ad$Entropía)
```

##
```{r}
qplot(ad$Entropía, geom="histogram", bins = 40) +
  labs(title="Distribución de la entropía informática") +
  labs(x="Entropía", y="Cantidad")
```

## Viscosidad informática

La relación entre la entropía y el tiempo de ejecución conserva una relación lineal entre ellos, así tenemos que a mayor entropía mayor tiempo de ejecución se requerirá. Lo anterior puede definir una medida de viscosidad informática igual a 1 / tangente del ángulo de la línea recta, dado que un ángulo mayor refleja una viscosidad menor. Solo como observación, el proceso de búsqueda se comporta como un fluido de una mezcla de líquidos de diversa viscosidad.

##
```{r}
qplot(ad$Entropía, ad$Tiempo) +
  labs(title="Tiempo de ejecución y Entropía") +
  labs(x="Tiempo", y="Entropía")
```

Como puede observarse los datos presentan una combinación de casos en los cuales algunos se calculan muy rápido y otros no. Aquí, entonces, es importante el uso del cache inicial, por lo que internamente se ordena por municipio y localidad.

## Distribución del nivel

La mayoría de los registros llegan a estimarse a nivel de número exterior. En general se tiene la siguiente distribución:
```{r}
  ad$Nivel
```

##
```{r}
qplot(ad$Nivel) +
  labs(title="Histograma para nivel") +
  labs(x="Nivel", y="Cantidad")
```

Observe que los niveles de colonia y localidad son los menores.

## Error a nivel de número exterior

Cuando el error a nivel de número exterior no es cero, tiene la siguiente distribución de probabilidad:
```{r}
  summary(ad$Error[which(ad$Nivel == "Número exterior" & ad$Error > 0)])
```

##
```{r}
qplot(ad$Error[which(ad$Nivel == "Número exterior" & ad$Error > 0)], geom="histogram", bins = 30) +
  geom_density(col=2) + 
  labs(title="Distribución del error nivel de pie de casa") +
  labs(x="Error", y="Cantidad")
```

## Error a nivel de calle

Cuando el error a nivel de calle no es cero, tiene la siguiente distribución de probabilidad:

```{r}
  summary(ad$Error[which(ad$Nivel == "Calle" & ad$Error > 0)])
```

##
```{r}
qplot(ad$Error[which(ad$Nivel == "Calle" & ad$Error > 0)], geom="histogram", bins = 20) +
  geom_density(col=2) + 
  labs(title="Distribución del error nivel de calle") +
  labs(x="Error", y="Cantidad")
```

## Error a nivel de colonia

Cuando el error a nivel de colonia no es cero, tiene la siguiente distribución de probabilidad:
```{r}
  summary(ad$Error[which(ad$Nivel == "Colonia" & ad$Error > 0)])
```

##
```{r}
qplot(ad$Error[which(ad$Nivel == "Colonia" & ad$Error > 0)], geom="histogram", bins = 10) +
  geom_density(col=2) + 
  labs(title="Distribución del error nivel de colonia") +
  labs(x="Error", y="Cantidad")
```

## Nota técnica

Para este reporte se eligieron 600 direcciones sin remplazo y en cada procesamiento se utilizó un solo procesador a 2.2 Ghz. A parte se tiene un procesador exclusivo para Postgresql e independiente.

## Balance de hardware de máquina virtual (Big Data)

De la experiencia resultan los siguientes parámetros de configuración basado en el número de direcciones por localizar para un mismo archivo subido. El tiempo depende del número de procesadores asignados a la máquina virtual y la memoría RAM depende de la cantidad de direcciones en un lote de trabajo. Cabe mencionar que el sistema requiere un procesador libre para el sistema y el uso del PostgreSQL, además de 1Gb de RAM.

##
Núm de procesadores asignados (CPU) | Procesadores dedicados (CPU) | Número de direcciones por localizar | Tiempo para terminar (días) | RAM para cálculo  (Gb)| RAM mínima (Gb) | RAM recomendada (Gb)
:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:
 4 |  3 |   250,000 | 5.0 | 2 | 3 |  4
 7 |  6 |   500,000 | 5.0 | 4 | 5 |  6
13 | 12 | 1,000,000 | 5.0 | 8 | 9 | 10
25 | 24 | 1,000,000 | 2.5 | 8 | 9 | 10
30 | 29 | 1,000,000 | 2.1 | 8 | 9 | 10

Considerar como referencia que para un archivo de Excel (versión 2007 y 2010) el máximo de renglones es de 1,048,576 por pestaña.

##
En general, se recomienda para una máquina virtual asignarle el mayor número de procesadores posible de la máquina física, igualmente para la memoria RAM. Y dependiendo de la memoria RAM es el límite de la cantidad de direcciones que puede procesar un lote.

La máquina de prueba utiliza 7896MiB de memoria RAM y cuenta con un procesador Intel(R) Core(TM) i5-2310 CPU @ 2.90GHz con capacidad de 3200MHz con 64 bits. A la máquina virtual se le asignaron 5Gb de RAM y 4 CPU's. Durante el procesamiento utiliza 2.5G de RAM.
